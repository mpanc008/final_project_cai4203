{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d71ec6b5b408ee99",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T16:58:58.965926Z",
     "start_time": "2025-07-10T16:58:58.926940Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "953f68d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def flatten_folder(source_dir, target_dir):\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "    for root, dirs, files in os.walk(source_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.JPG', '.PNG', '.JPEG')):\n",
    "                src_path = os.path.join(root, file)\n",
    "                dst_path = os.path.join(target_dir, file)\n",
    "                shutil.copy2(src_path, dst_path)\n",
    "\n",
    "# Example usage:\n",
    "flatten_folder(\"C:/data/wiki\", \"data/real\")\n",
    "flatten_folder(\"C:/data/inpainting\", \"data/fake\")\n",
    "\n",
    "\n",
    "print(len(os.listdir(\"data/real\")))\n",
    "print(len(os.listdir(\"data/fake\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ee301f12cb2b15",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73c7791aedfe16eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T17:50:32.516153Z",
     "start_time": "2025-07-10T17:49:45.170615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60000 files belonging to 2 classes.\n",
      "Using 48000 files for training.\n",
      "Found 60000 files belonging to 2 classes.\n",
      "Using 12000 files for validation.\n",
      "Class names: ['fake', 'real']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# --------- CONFIG ---------\n",
    "image_size = (224, 224)\n",
    "batch_size = 200\n",
    "data_dir = \"data\"  # Make sure 'data/real/' and 'data/fake/' exist\n",
    "\n",
    "# --------- LOAD RAW DATASETS ---------\n",
    "# Load before any .map() so we can access class_names\n",
    "raw_train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "raw_val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "# --------- CLASS NAMES ---------\n",
    "class_names = raw_train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(\"Class names:\", class_names)\n",
    "\n",
    "# --------- NORMALIZATION & PIPELINE OPTIMIZATION ---------\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = (\n",
    "    raw_train_ds\n",
    "    .map(lambda x, y: (normalization_layer(x), y))\n",
    "    .cache()\n",
    "    .shuffle(1000)\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "\n",
    "val_ds = (\n",
    "    raw_val_ds\n",
    "    .map(lambda x, y: (normalization_layer(x), y))\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca29b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1184s\u001b[0m 4s/step - accuracy: 0.5072 - loss: 1.1285 - val_accuracy: 0.5815 - val_loss: 0.6705\n",
      "Epoch 2/10\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m952s\u001b[0m 4s/step - accuracy: 0.6096 - loss: 0.6540 - val_accuracy: 0.7483 - val_loss: 0.5227\n",
      "Epoch 3/10\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m915s\u001b[0m 4s/step - accuracy: 0.7632 - loss: 0.4885 - val_accuracy: 0.7831 - val_loss: 0.4506\n",
      "Epoch 4/10\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m932s\u001b[0m 4s/step - accuracy: 0.8693 - loss: 0.3086 - val_accuracy: 0.9408 - val_loss: 0.1372\n",
      "Epoch 5/10\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2815s\u001b[0m 12s/step - accuracy: 0.9724 - loss: 0.0754 - val_accuracy: 0.9759 - val_loss: 0.0715\n",
      "Epoch 6/10\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m891s\u001b[0m 4s/step - accuracy: 0.9924 - loss: 0.0243 - val_accuracy: 0.9538 - val_loss: 0.1501\n",
      "Epoch 7/10\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m790s\u001b[0m 3s/step - accuracy: 0.9930 - loss: 0.0220 - val_accuracy: 0.9705 - val_loss: 0.0955\n",
      "Epoch 8/10\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m834s\u001b[0m 3s/step - accuracy: 0.9957 - loss: 0.0138 - val_accuracy: 0.9613 - val_loss: 0.1293\n",
      "Epoch 9/10\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m927s\u001b[0m 4s/step - accuracy: 0.9907 - loss: 0.0253 - val_accuracy: 0.9667 - val_loss: 0.1054\n",
      "Epoch 10/10\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m811s\u001b[0m 3s/step - accuracy: 0.9577 - loss: 0.1099 - val_accuracy: 0.9714 - val_loss: 0.1024\n"
     ]
    }
   ],
   "source": [
    "# -------- MODEL DEFINITION ---------\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(224, 224, 3)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dropout(0.20),\n",
    "    tf.keras.layers.Dense(650, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.20),\n",
    "    tf.keras.layers.Dense(304, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.20),\n",
    "    tf.keras.layers.Dense(161, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.20),\n",
    "    tf.keras.layers.Dense(80, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.20),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# --------- TRAINING ---------\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    batch_size = 128\n",
    ")\n",
    "#batch_size?\n",
    "\n",
    "# --------- EVALUATE ON VALIDATION SET ---------\n",
    "loss, acc = model.evaluate(val_ds, verbose=1)\n",
    "\n",
    "print(f\"\\n✅ Evaluation Results:\")\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {acc:.4f}\")\n",
    "\n",
    "#---Plot\n",
    "\n",
    "\n",
    "#Accuracy Plot\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Loss Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
